---
title: "B201599_dissertation_code"
author: "B201599"
date: "18/08/2022"
output: html_document
---

## R Markdown

```{r packages, echo=FALSE}

install.packages("pak")
library(pak)
pak::pkg_install("r-lib/rlang")
install.packages("devtools")
library(devtools)
install_github("vqv/ggbiplot")
library(ggbiplot)
install.packages("https://cran.r-project.org/bin/windows/Rtools/", repo = NULL, type="source")
install_github("cma2015/rsgcc")
library(rsgcc)  
#library(philentropy)
install.packages("BiocManager")
BiocManager::install("ctc")


install.packages('matrixcalc')
library('matrixcalc')

install.packages('pdist')
library(pdist)


install.packages("pROC")
library(pROC)


install.packages("randomForest")
library(randomForest)

#BiocManager::install("pcaExplorer")

install.packages("snowfall")
library(snowfall)

install.packages("e1071")
#sfLibrary("e1071")
library(e1071)


install.packages("psych",dependencies=TRUE)
library("psych")

install.packages("neuralnet")
library(neuralnet)
install.packages("nnet")
library(nnet)

install.packages("igraph")
library(igraph)

library(dplyr)


BiocManager::install("clusterProfiler")
BiocManager::install("enrichplot")
library(clusterProfiler)
library(enrichplot)
library(ggplot2)
library(DOSE)
library(GOSemSim)


BiocManager::install("ggridges")
library(ggridges)

BiocManager::install("europepmc")
library(europepmc)


devtools::install_github("javadnoorb/pathview")
library(pathview)

install.packages("reshape2")
library(reshape2)

install.packages("bigmemory")
library(bigmemory)


install.packages("ROCR")
library(ROCR)


BiocManager::install("fBasics")
library(fBasics)


install.packages("data.table")                     
library("data.table")   

BiocManager::install("mclust")
BiocManager::install("hardhat")
library(hardhat)
library(mclust)
BiocManager::install("caret")
library(caret)


organism = "org.At.tair.db"
BiocManager::install(organism, character.only = TRUE)
library(organism, character.only = TRUE)

BiocManager::install("pRoloc")
library(pRoloc)

install.packages("cvms")
library(cvms)
library(tibble)

install.packages("sf")
library(sf)
posinstall.packages("ggVennDiagram")
library(ggVennDiagram)

install.packages("cowplot")
library(cowplot)
install.packages("ggpubr")
library(ggpubr)

BiocManager::install("edgeR")
library(edgeR)

install.packages("ggvenn")              
library("ggvenn")     
```   

```{r loading_data, echo=TRUE}

# LOADING THE DATA
lateral_root_data <- read.table("~/Google Drive/My Drive/Dissertation- G drive/lateral_root_IAA.csv", sep = ",", header = TRUE)
rownames(lateral_root_data) <- lateral_root_data$Identifier
ControlExpMat <- as.matrix(lateral_root_data[ c("Col_NPA_0h_1_exp_LRIvanneste", "Col_NPA_0h_2_exp_LRIvanneste")])
SucroseExpMat2 <- as.matrix(lateral_root_data[ c("Col_NAA_2h_1_exp_LRIvanneste", "Col_NAA_2h_2_exp_LRIvanneste")])
SucroseExpMat3 <- as.matrix(lateral_root_data[ c("Col_NAA_6h_1_exp_LRIvanneste", "Col_NAA_6h_2_exp_LRIvanneste")])
expMat1 = ControlExpMat
expMat2 = SucroseExpMat2
expMat3 = SucroseExpMat3
sampleVec1 <- c(1.1, 1.2)
sampleVec2 <- c(2.1, 2.2)

```


## Global functions
```{r global_fun, echo=TRUE}

checkadjmatrix <- function( mat, backingpath = NULL, descriptorfile = NULL ) {

  
  descfile <- NULL
  if( is.big.matrix(mat) ) {
    if( is.null(backingpath) | is.null(descriptorfile) ) {
      stop("Error: backingpath and descriptorfile should be specified for big.matrix")
    }
    descfile <- paste( backingpath, descriptorfile, sep="")
  }
  
  if( is.null(rownames(mat)) ) {
    stop("Error: no rownames for mat")
  }
  
  descfile
}





##get system time for seed and then generate random index
randomSeed <- function() {
  curtime <- format(Sys.time(), "%H:%M:%OS4")
  XXX <- unlist(strsplit(curtime, ":"))
  curtimeidx <- (as.numeric(XXX[1])*3600 + as.numeric(XXX[2])*60 + as.numeric(XXX[3]))*10000
  curtimeidx
}




#Function: get indexes of one vector from another vector
##add 20130326
getIndex <- function( VecTarget, VecTo ){
  res <- match( VecTo, VecTarget )
  names(res) <- VecTo
  res
}



##coefficient of variance
cv <- function( vec ) {
  return( sd(vec)/mean(vec) )
}


##expression z-score
matZScore <- function( mat ) {
  mean <- apply( mat, 1, mean )
  sd <- apply( mat, 1, sd )
  zMat <- sweep( mat, MARGIN=1, mean, '-' )
  zMat <- sweep( zMat, MARGIN=1, sd, '/' )
  zMat
}


##Exponential function
expFun <- function( x, base = exp(1)) {
  
  if( base == exp(1) ) {
     return( exp(x) )
  }else{
     return( base^x )
  }
}

adjacencymatrix <- function(expMatx){
  library(igraph)
  adjg <- graph.adjacency(
  as.matrix(as.dist(cor(t(expMatx), method="pearson"))),
  mode="undirected",
  weighted=TRUE,
  diag=FALSE
)
  adjacency_matrix <- get.adjacency(adjg)
  return(adjacency_matrix)
}

##plot lines
plotLines <- function( xylist, xlim= NULL, ylim = NULL, colors, legends, legends.xpos, legends.ypos = NULL, lwd = 2, xlab = "", ylab = "", title = "", ... ) {
  
  call <- match.call()

  if( !is.list(xylist)  ) 
    stop("Error: xylist should be a list. For each component, there are two vectors respectively for x and y.")

  lineNum <- length(xylist)
  if( length(lwd) == 1 ) 
     lwd <- rep( lwd, lineNum )
  if( length(colors) != lineNum ) 
     stop("Error: conflict number between xylist and colors.")
   
  yvalues <- c()
  for( ii in 1:lineNum ) {
     yvalues = c(yvalues, xylist[[ii]]$y )
  }
  if( is.null(ylim) )
    ylim = range(0, range(yvalues) )

  for( ii in 1:lineNum ) {
     curData <- xylist[[ii]]
    
    if( ii == 1 ) {
      plot(curData$x, curData$y, ylim = ylim, lwd = lwd[ii],  xlab=xlab, ylab=ylab, type="l", col= colors[ii], main=title, ...)
    }else {
      lines(curData$x, curData$y, lwd = lwd[ii], col= colors[ii], ...)
    }
  }
  
  legend(x = legends.xpos, y=legends.ypos, legend=legends, lty=rep(1, lineNum), col = colors, lwd = lwd, ... )
}



##
EDist <- function( v1, v2, sizeNormalized = FALSE ) {

  score <- sqrt( sum( (v1-v2)^2) )
  if( sizeNormalized == TRUE )
    score <- score/sqrt( length(v1) )

  return(score)
}



```
  
  
## calculating the z-scores for the feature matrix  
```{r expression_comparison, echo=TRUE}
  
  
  #Function: gene expression comparision for two different biologically condtions
  ##base: numeric or EXP
difExp <- function( expMat1, sampleVec1, expMat2, sampleVec2, logTransformed = TRUE, base = 2 ){
  
checkExpMat(expMat1, sampleVec1, expMat2, sampleVec2)
    
    sample.un1 <- unique(sampleVec1)
    
    result <- matrix( 0, nrow = nrow(expMat1), ncol= length(sample.un1))
    rownames(result) <- rownames(expMat1)
    colnames(result) <- sample.un1
  
    ##exp mean
    expMat1.mean <- expMean( expMat = expMat1, sampleVec = sampleVec1, samplelabel = NULL, logTransformed = logTransformed, base = base )
    expMat2.mean <- expMean( expMat = expMat2, sampleVec = sampleVec2, samplelabel = NULL, logTransformed = logTransformed, base = base )
  
    #fcmean1 <- apply(expMat1, 1, mean)
    #fcmean2 <- apply(expMat2, 1, mean)
    expMat1.mean_org <- expMat1.mean
    expMat2.mean_org <- expMat2.mean
    if( logTransformed == TRUE ) {
       expMat1.mean_org <- expFun( expMat1.mean, base )
       expMat2.mean_org <- expFun( expMat2.mean, base )
    }
  
    ##exp z-score
    zScore1 <- matZScore( expMat1.mean_org )
    zScore2 <- matZScore( expMat2.mean_org )
  
    ##fold change  
    fcMat <- NULL
    if( logTransformed == TRUE ) {
       fcMat <- expMat2.mean - expMat1.mean
    }else {
       fcMat <- log( expMat2.mean_org/expMat1.mean_org, base)
    }
    colnames(fcMat) <- paste( "fc", sample.un1, sep = "" )
    
    
    return( list(expMat1.mean = expMat1.mean, expMat2.mean = expMat2.mean, zScore1 = zScore1, zScore2 = zScore2, fcMat = fcMat ) )
  }
  
  #difExp( expMat1, sampleVec1, expMat2, sampleVec2, logTransformed = TRUE, base = 2 )
  
```
  
  
### Function to create the input feature matrix by calculating the z-scores and coeficcient of variations of data  
```{r expression_features, echo=TRUE}
  
  ##Functions: generating express-based features 
expFeatureMatrix <- function( expMat1, sampleVec1, expMat2, sampleVec2, logTransformed = TRUE, base = 2, 
                                features = c("zscore", "foldchange", "cv", "expression")) {
      
    res <- difExp( expMat1, sampleVec1, expMat2, sampleVec2, logTransformed, base )
  
    sampleUnique <- unique( sampleVec1 )
    
    featureMat <- matrix( 0, nrow = nrow(expMat1), ncol = 1)
    colnames(featureMat) <- "tmp"
    for( ii in 1:length(features) ){
      tmp <- NULL
      if( features[ii] == "zscore" ) {
        tmp <- c( colnames(featureMat), paste( "zScore1", sampleUnique, sep = "_"), paste( "zScore2", sampleUnique, sep = "_") )
        featureMat <- cbind(featureMat, res$zScore1, res$zScore2)
      }else if( features[ii] == "foldchange"  ) {
        tmp <- c( colnames(featureMat), paste( "foldchange", sampleUnique, sep = "_"))
        featureMat <- cbind( featureMat, res$fcMat )
      }else if( features[ii] == "cv" ){
        cv1 <- apply( res$expMat1.mean, 1, cv )
        cv2 <- apply( res$expMat2.mean, 1, cv )
        tmp <- c( colnames(featureMat), "cv1", "cv2" )
        featureMat <- cbind( featureMat, cv1, cv2 )
      }else if( features[ii] == "expression" ) {
        tmp <- c( colnames(featureMat), paste( "expression1", sampleUnique, sep = "_"), paste( "expression2", sampleUnique, sep = "_") )
        featureMat <- cbind( featureMat, res$expMat1.mean, res$expMat2.mean )  
      }else {
        stop("Error: undefined expression-based features")
      }
      colnames(featureMat) <- tmp
    }#end for ii
    featureMat <- featureMat[,-1]
    return(featureMat)
}


```


### Creating a feature matrix based on microarray and RNA-seq data
```{r feature_mat, echo=FALSE}
  
feature_matrix <- expFeatureMatrix(expMat1, sampleVec1, expMat2, sampleVec2, logTransformed = TRUE, base = 2, features = c("zscore", "cv", "expression"))

# FOR LATERAL ROOT DATASET
feature_mat_6 <- expFeatureMatrix(expMat1, sampleVec1, expMat3, sampleVec2, logTransformed = TRUE, base = 2, features = c("zscore", "cv", "expression"))

### FOR WHOLE ROOT DATASET
feature_matrix <- merge(feature_matrix, root_math, by=0, all=TRUE)
rownames(feature_matrix) <- feature_matrix$Row.names
feature_matrix <- subset(feature_matrix, select = -Row.names)
feature_matrix <- as.matrix(feature_matrix)
if (any(is.na(feature_matrix))){
  feature_matrix <- na.omit(feature_matrix)
}
lateral_root_genes_final <- intersect(lateral_root_genes, rownames(feature_matrix))
feature_matrix <- feature_matrix[lateral_root_genes_final, ]


featureMat <- feature_matrix
```


### creating the inital negative set by collecting all ribosomal and mitochondrial genes

```{r negative_unncessary_genes, echo=TRUE}
## NEGATIVE GENES
mitochondria_rows <- rownames(featureMat[rownames(featureMat) %like% "ATM", ])


negatives <- c(ribosomal, mitochondria, mitochondria_rows)
negatives <- unique(negatives)
negatives <- as.data.frame(negatives)
positives <- as.data.frame(positives)


neg <- intersect(negatives$negatives, rownames(featureMat))
positives <- as.data.frame(positives)
pos <- intersect(positives$positives, rownames(featureMat))
positiveSamples <- pos
negativeSamples <- neg

negativeSamples <- setdiff(negativeSamples, positiveSamples)

# finding the negative genes farthest from the positive genes based on Euclidean distance
positiveSamples_matrix <- feature_matrix[positiveSamples, ]
negativeSamples_matrix <- feature_matrix[negativeSamples, ]
dists_neg <- pdist(negativeSamples_matrix, positiveSamples_matrix)
distance_matrix <- as.matrix(dists_neg)
rownames(distance_matrix) <- rownames(negativeSamples_matrix)
colnames(distance_matrix) <- rownames(positiveSamples_matrix)
distance_matrix_df <- as.data.frame(distance_matrix)
df_final <- data.frame(matrix(0, nrow = 4275, ncol=1))
for (x in positiveSamples) {
  rankv= "Rank"
  rank_var_new=paste(rankv, x, sep="_" )
  print(rank_var_new)
  rank_var_newx <- apply(distance_matrix_df[x], 2, rank)
  df_final[rank_var_new] <- rank_var_newx
}

df_final_test <- subset(df_final, select = -matrix.0..nrow...4275..ncol...1.)
head(df_final_test)
average_rank <- rowMeans(df_final_test)
df_final_test <- cbind(df_final_test, average_rank)
rownames(df_final_test) <- rownames(negativeSamples_matrix)
data_rank <- df_final_test[order(-average_rank),]
number_positive_set <- nrow(positiveSamples_matrix)
rows_max_ed <- rownames(head(data_rank, number_positive_set))
negativeSamples <- rows_max_ed
number_negative_set <- nrow(as.data.frame(negativeSamples)) 
rows_max_ed <- rownames(head(data_rank, number_negative_set)) 
rows_max_ed <- rownames(head(positiveSamples, number_negative_set))


unlabelSamples <- setdiff( rownames(featureMat), negativeSamples )
unlabelSamples <- setdiff( unlabelSamples, positiveSamples)


```


```{r ML_functions, echo=TRUE}
############################################################
##general functions in ML


#Function: get sample index for cv cross validation
cvSampleIndex <- function( len, cross = 5, seed = 1 ) {
  
  cv <- cross
  sample_matrix <- matrix(0, nrow = len, ncol = cv)
  colnames(sample_matrix) <- paste("cv", c(1:cv), sep = "" )
  
  #random samples 
  set.seed(seed)
  index <- sample(1:len, len, replace = FALSE )
  step = floor( len/cv )
  
  start <- NULL
  end <- NULL
  train_lens <- rep(0, cv)
  for( i in c(1:cv) ) {
    start <- step*(i-1) + 1
    end <- start + step - 1
    if( i == cv ) 
      end <- len
    
    train <- index[-c(start:end)]
    test <- index[start:end]
    train_lens[i] <- length(train)
    
    sample_matrix[,i] <- c(train, test)
  }#end for i
  
  return( list( train_lens = train_lens, sample_matrix = sample_matrix))
}





##prediction for different ML approaches
##ml: machine learning type
##ml = rf, mlParaList include ntree and samplesize, see parameter introduction in randomForest package
##ml = bn, mlParaList includ laplace, see parameter introduction in e1071 package
##degree, gamma, coef0, cost, nu, class.weights, epsilon, kernel(polynomial, linear, radial)  svm parameters
##mtry, nodesize, ntree  randomForest parameters
##size, decay, trace  parameters passed to nnet.
##classifier( method = "randomForest", featureMat= featureMat, positiveSamples = positiveSamples, negativeSamples= negativeSamples, ntree = 200, mytry = c(5, 8, 10))
##objsvm <- classifier( method = "svm", featureMat = featureMat, positiveSamples = positiveSamples, negativeSamples = negativeSamples, gamma = 2^(-1:1), cost = 2^(2:4), kernel = "radial")
##objnnet <- classifier(method = "nnet", featureMat = featureMat, positiveSamples = positiveSamples, negativeSamples = negativeSamples, size = 20)
classifier <- function( method = c("randomForest", "svm", "nnet", "knn"), featureMat, positiveSamples, negativeSamples, tunecontrol = tune.control(sampling = "cross", cross = 5), ...) {
  call <- match.call()
  
  if( length(method) > 1) 
    method <- method[1]

  if( is.null(rownames(featureMat) ) )
    stop("Error: no row names (i.e., sample IDs) were assigned for featureMat." )
  if( is.null(colnames(featureMat) ) )
    stop("Error: no colnames were defined for featureMat." )

  positiveSamples <- intersect( rownames(featureMat), positiveSamples )
  negativeSamples <- intersect( rownames(featureMat), negativeSamples )
  posLen <- length(positiveSamples)
  negLen <- length(negativeSamples)
  if( posLen == 0 )
    stop("Error: no positive samples included in featureMat." )
  if( negLen == 0 )
    stop("Error: no negative samples were included in featureMat." )

  label <- c( rep(1, posLen), rep(0, negLen) )
  fmat <- data.frame( featureMat[c(positiveSamples, negativeSamples), ] )
  tmpData <- cbind( fmat, label )
  colnames(tmpData) <- c(colnames(fmat), "Class")
  if( method == "randomForest" ) {
    obj <- tune.randomForest( x = fmat, y = factor(label), tunecontrol = tunecontrol, ...)
  }else if( method == "svm" ){
    obj <- tune.svm( Class~., data = data.frame(tmpData), tunecontrol = tunecontrol, ... )
  }
  else if( method == "knn" ){
    obj <- tune.knn( x = fmat, y = factor(label), tunecontrol = tunecontrol, ... )
  }
  else if( method == "nnet" ){
    obj <- tune.nnet( Class~., data = data.frame(tmpData), tunecontrol = tunecontrol, ... )
  }
  obj
}
  




## Predictor function to predict the prediction scores of unlabelled genes  
predictor <- function( method = c("randomForest", "svm", "nnet", "knn"), classifier, featureMat ) {
  if( method == "randomForest") {
    res <- predict(classifier, data.frame(featureMat), type= "vote" )[,"1"]
  }else if( method == "knn"){
    library(caret)
    res <- predict(classifier, data.frame(featureMat), type= "vote" )[,"1"]
  }
  else {
    res <- predict( classifier, data.frame(featureMat), type = "raw") 
  }
  names(res) <- rownames(featureMat)
  res
}



# Selecting the classifier with max AUC as the final model
find_ClassifierWithMaxAUC <- function( cvRes ) {
  
  classifier <- NA
  maxAUC <- 0
  for( i in 1:length(cvRes) ) {
     res <- cvRes[[i]]
     if( res$test.AUC > maxAUC) {
        maxAUC <- res$test.AUC
        classifier <- res$classifier
     }
  }#end for i
  
  return( list(maxAUC = maxAUC, classifier = classifier))
}



obtain_CV_AUCMat <- function( cvRes ) {
  cv <- length(cvRes)
  AUCMat <- matrix(0, nrow = cv, ncol = 2 )
  rownames(AUCMat) <- paste( "cv", 1:cv, sep = "" )
  colnames(AUCMat) <- c("trainingSet", "testingSet")
   
  for( i in 1:cv ) {
    res <- cvRes[[i]]
    AUCMat[i,2] <- res$test.AUC
    AUCMat[i,1] <- res$train.AUC
  }#end for i
  
  AUCMat
}






## cross-validation function
one_cross_validation <- function( cv, method, featureMat, positives, negatives, posSample_cv, negSample_cv, balanced = TRUE, ratio = 10, ... ) {
  call <- match.call()
  j <- cv
  
  #for train samples
  train_genes_p <- positives[ (posSample_cv$sample_matrix[,j][1:posSample_cv$train_lens[j]] ) ]
  test_genes_p <- positives[ (posSample_cv$sample_matrix[,j][-c(1:posSample_cv$train_lens[j])]) ]
  
  #trained negatives randomly selected, and tested on all negatives
  train_genes_n <- negatives[(negSample_cv$sample_matrix[,j][1:negSample_cv$train_lens[j]] ) ]
  test_genes_n <- negatives[ (negSample_cv$sample_matrix[,j][-c(1:negSample_cv$train_lens[j])]) ]
  
   #select part of train_genes_n
   if( balanced == TRUE ) {
      if( length(train_genes_n) > ratio*length(train_genes_p) ) {
        train_genes_n <- negatives[sample(1:length(train_genes_n), replace=FALSE)[1:(ratio*length(train_genes_p))]]
      }
   }
        
    
  
  obj <- classifier( method = method, featureMat = featureMat, positiveSamples = train_genes_p, negativeSamples = train_genes_n, ... )
  bestmodel <- obj$best.model
  
  positives.train.score <- predictor( method = method, classifier = bestmodel, featureMat = featureMat[train_genes_p,])
  negatives.train.score <- predictor( method = method, classifier = bestmodel, featureMat = featureMat[train_genes_n,])
  positives.test.score <- predictor( method = method, classifier = bestmodel, featureMat = featureMat[test_genes_p,])
  negatives.test.score <- predictor( method = method, classifier = bestmodel, featureMat = featureMat[test_genes_n,])
  


  train.AUC <- roc( c(rep(1, length(train_genes_p)), rep(0, length(train_genes_n))), 
                    c(positives.train.score, negatives.train.score) )$auc[1]
  test.AUC <- roc( c(rep(1, length(test_genes_p)), rep(0, length(test_genes_n))), 
                   c(positives.test.score, negatives.test.score) )$auc[1]
  
  res <- ( list( positves.train = train_genes_p, negatives.train = train_genes_n, 
                        positives.test = test_genes_p, negatives.test = test_genes_n, 
                        ml = method, classifier = bestmodel, 
                        positives.train.score = positives.train.score,
                        negatives.train.score = negatives.train.score,
                        positives.test.score = positives.test.score,
                        negatives.test.score = negatives.test.score,
                        train.AUC = train.AUC,
                        test.AUC = test.AUC) )
  
  res
}



# executing the cross-validation function by loading all the machine learning packages in parallel using snowflake.
cross_validation <- function( seed = 1, method = c("randomForest", "svm", "nnet" , "knn"), featureMat, positives, negatives, cross = 5, cpus = 1, ... ){
  
  call <- match.call()

  #sample index for cv
  posSample_cv <- cvSampleIndex(length(positives), cross = cross, seed = seed)
  negSample_cv <- cvSampleIndex(length(negatives), cross = cross, seed = seed)
  
  cvRes <- list()
  if( cpus > 1 ) {
    #require(snowfall)
    sfInit(parallel = TRUE, cpus = cpus)
    sfExport("classifier", namespace = "mlDNA")
    sfExport("predictor", namespace = "mlDNA")
    sfExport("one_cross_validation", namespace = "mlDNA")
    sfLibrary( "pROC", character.only=TRUE)
    sfLibrary( "e1071", character.only=TRUE)
    sfLibrary( "randomForest", character.only=TRUE )
    sfLibrary( "nnet", character.only=TRUE )
    #sfLibrary( "caret", character.only=TRUE )
       
    cvRes <- sfApply( matrix(1:cross, ncol = 1), 1,  one_cross_validation, method = method, featureMat = featureMat, positives = positives, negatives = negatives, posSample_cv = posSample_cv, negSample_cv = negSample_cv, ...)
    sfStop()
  }else {
    for( j in 1:cross ) {
      cvRes[[j]] <- one_cross_validation( cv = j, method = method, featureMat = featureMat, positives = positives, negatives = negatives, posSample_cv = posSample_cv, negSample_cv = negSample_cv, ... )
    }
  }
  cvRes
}


plotROC <- function(cvRes) {

 
   cvListPredictions <- list()
   cvListLabels <- list()
   AUCVec <- rep(0, length(cvRes) )
   for( i in 1:length(cvRes) ) {
      curCV <- cvRes[[i]]
      cvListPredictions[[i]] <- c( curCV$positives.test.score, curCV$negatives.test.score )
      cvListLabels[[i]] <- c( rep(1, length(curCV$positives.test.score)), rep(0, length(curCV$negatives.test.score) ) )
      AUCVec[i] <- curCV$test.AUC
   }
   mAUC <- format( mean(AUCVec), digits= 3)

    #if( !require(ROCR) ) {
    #   install.packages("ROCR")
    #   library(ROCR)
    #}
    pred <- prediction(cvListPredictions, cvListLabels)
    perf <- performance(pred,"tpr","fpr")
      

    par(mar=c(5,6,4,2))   
    plot(perf, col= "gray", lty=3, main = paste( "AUC = ", mAUC, sep = ""), cex.lab = 2.5, cex.axis = 2, cex.main = 3, mgp = c(4,1.8,0) )
    plot(perf, col = "black",  lwd= 3, avg="vertical", spread.estimate="none", add=TRUE)  

}

```


### Predicting the optimal score using 10-fold cross-validation based on F-beta score
```{r optimal_score, echo=TRUE}


###F-score analysis for find optimal prediction score
optimalScore <- function( positiveSampleScores, negativeSampleScores, beta = 2, plot = TRUE ) {
   lengthx <- length(positiveSampleScores)
   positives <- paste( "positive", 1:length(positiveSampleScores), sep = "" )
   negatives <- paste( "negative", 1:length(negativeSampleScores), sep = "" )
   scoreVec <- c( positiveSampleScores, negativeSampleScores )
   names(scoreVec) <- c(positives, negatives)
   
    #score range
    scoreVec.unique <- sort( unique(scoreVec), decreasing= F )
    mccMat <- matrix( 0, nrow = length(scoreVec.unique), ncol = 12 ) 
    colnames(mccMat) <- c("cutoff", "TP", "FP", "TN", "FN", "TPR(Recall)", "TNR(Specificity)", "Precision", "F-score", "Accuracy", "FPR", "FNR")


    for( i in 1:length(scoreVec.unique) ) {
      curScore <- as.numeric( scoreVec.unique[i] )
      gotGenes <- names(scoreVec)[ which(scoreVec >= curScore) ]
      TP <- length( intersect( positives, gotGenes) )
      FP <- length(gotGenes) - TP
      TN <- length(negatives) - FP
      FN <- length(positives) - TP
      
      
      mccMat[i,1] <- curScore
      mccMat[i,2] <- TP
      mccMat[i,3] <- FP
      mccMat[i,4] <- TN
      mccMat[i,5] <- FN
      mccMat[i,10] <- (TP+TN)/(TP+FP+FN+TN)# Accuracy
      mccMat[i,11] <- (FP)/(FP+TN)#FPR
      mccMat[i,6] <- 1.0*TP/(TP+FN)  #TPR
      mccMat[i,7] <- 1.0*TN/(TN+FP) #TNR
      mccMat[i,8] <- 1.0*TP/(TP+FP) #ppv, precision
      mccMat[i,12] <- (FN)/(FN+TP)#FNR
      
            
      beta <- 2
      mccMat[i,9] <- (beta^2+1)*mccMat[i,6]*mccMat[i,8]/( mccMat[i,6] + beta*mccMat[i,8] ) ##here beta for different weight, 20130617
      
      #not consider MCC
      #mccMat[i,11] <- 1.0*(TP+TN)/(TP+FP+TN+FN)
      #mccMat[i,12] <- 1.0*(TP*TN-FP*FN)/( sqrt(TP+FN)* sqrt(TN+FP) *sqrt(TP+FP) *sqrt(TN+FN) ) 
    }
 

    ##get optimal prediction score
    Max <- sort( mccMat[,9], decreasing= T)[1]
    idx2 <- which( mccMat[,9] == Max )[1]
    optimalThreshold <-  mccMat[idx2, 1]
    
    Min <- sort( mccMat[,12], decreasing= F)[1]
    idx2x <- which( mccMat[,12] == Min )[1]
    optimalThresholdx <-  mccMat[idx2x, 1]
   
    if( plot ){
      plot( mccMat[,1], mccMat[,9], type= 'l', lwd = 2, col = "black", xlab = "Threshold", ylab = "F-score", main = paste( "optimal score = ", optimalThreshold, sep = "") )
      abline( v = optimalThreshold, col = "gray", lty = 2)
      df <- as.data.frame(mccMat[,11],mccMat[,6])
      plot(mccMat[,11],mccMat[,6], type="l",col="red", xlab = "FPR", ylab = "TPR") 
      abline(coef = c(0.00000,1), col = "gray", lty=2, lwd=3)
      ggplot(df, )
      #plot(mccMat[, 1], mccMat[, 12],col="green")
      #lines(mccMat[,1], mccMat[,6],col="green")
      #lines(mccMat[,1], mccMat[,8],col="blue")
      #legend(0,3,legend=c("Accuracy","TPR","FPR"), col=c("red","green","blue"),lty=c(1,2,3), ncol=1)
    }

   res <- list( statMat = mccMat, optimalScore = optimalThreshold )
   res
}






```


## Setting the hyperparameters for each ML model
```{r hyperparameters, echo=TRUE}
# building the cross-validation dataset with initial positive and negative sets
positiveSamples <- intersect( rownames(featureMat), positiveSamples )
negativeSamples <- intersect( rownames(featureMat), negativeSamples )
posLen <- length(positiveSamples)
negLen <- length(negativeSamples)
label <- c( rep(1, posLen), rep(0, negLen) )
fmat <- data.frame( featureMat[c(positiveSamples, negativeSamples), ] )
tmpData <- cbind( fmat, label )
colnames(tmpData) <- c(colnames(fmat), "Class")
tmpData$Class <- as.factor(tmpData$Class)
levels(tmpData$Class) <- c("negative", "positive")

# stratified random split
seed <- 123
set.seed(seed)
train.index <- createDataPartition(tmpData$Class, p = .7, list = FALSE)
training <- tmpData[ train.index,]
training$Class <- as.factor(training$Class)
levels(training$Class) <- c("negative", "positive")
testing  <- tmpData[-train.index,]
testing$Class <- as.factor(testing$Class)
levels(testing$Class) <- c("negative", "positive")

# Correlation matrix
cor_matrix<-abs(cor(training))
diag(cor_matrix)<-0
library(corrplot)
corrplot(cor_matrix, method="square")

# Performing PCA 
prComp<-prcomp(training[,-ncol(training)],center = TRUE, scale. = TRUE)
std_dev <- prComp$sdev
pr_var <- std_dev^2
prop_varex <- pr_var/sum(pr_var)
pcsum <- sum(prop_varex[1:8])
png(filename="~/Google Drive/My Drive/Dissertation- G drive/Arabi/sucrose_in_lateral_root/pc_final_8_0.9618.png", res=600, width=4800, height=4800, pointsize=10,)
plot(cumsum(prop_varex), xlab = "Principal Component",ylab = "Cumulative Proportion of Variance Explained",type = "b")
abline(h=pcsum,col='red',v=8)
dev.off()

## PLOT THE PCA

g <- ggbiplot(prComp,
              obs.scale = 1,
              var.scale = 1,
              groups = training$Class,
              ellipse = TRUE,
              circle = TRUE,
              ellipse.prob = 0.68)
g <- g + scale_color_discrete(name = '')
g <- g + theme(legend.direction = 'horizontal',
               legend.position = 'top')
png(filename="~/Google Drive/My Drive/Dissertation- G drive/Arabi/sucrose_in_lateral_root/pca_final_labels_genes.png", res=600, width=4800, height=4800, pointsize=10,)
g
dev.off()

# Reducing the dimensions of the data based on cumulative variance
seed <- 123
set.seed(seed)
train.data<-data.frame(Class = training$Class, prComp$x)
train.data <- train.data[,1:9]


# HYPERPARAMETER TUNING SVM

tune_out_svm <- tune.svm(x = train.data[, -1], y = as.factor(train.data$Class),  type = "C-classification", kernel = "radial",cost = c(.01, 0.1, 0.5, 1, 2.5, 5), gamma = c(0.01,0.1,0.5, 1,5), scale = FALSE)
performance_svm <- as.data.frame(tune_out_svm$performances, id = rownames(performance_svm))
g1gamma <- ggplot(performance_svm, aes(x= gamma, y=error, color=error))+ geom_point() + geom_smooth()+geom_point(data=performance_svm[rownames(tune_out_svm$best.parameters), ], aes(x= gamma, y=error), colour="red", size=5) 
g1cost <- ggplot(performance_svm, aes(x= cost, y=error, color=error, palette = "green"))+ geom_point() + geom_smooth()+geom_point(data=performance_svm[rownames(tune_out_svm$best.parameters), ], aes(x= cost, y=error), colour="red", size=5)
g1both <- ggplot(performance_svm, aes(x= gamma, y=cost, color=error, palette = "jco"))+ geom_point() + geom_smooth()+geom_point(data=performance_svm[rownames(tune_out_svm$best.parameters), ], aes(x=gamma, y=cost), colour="red", size=5)
png(filename="~/Google Drive/My Drive/Dissertation- G drive/Arabi/sucrose_in_lateral_root/sv_tune_gamma_0.1_cost_5_error_0.2709.png", res=600, width=8800, height=4800, pointsize=10,)
ggarrange(g1gamma, g1cost, g1both, 
          labels = c("A", "B", "C"),
          ncol = 3, nrow = 1)
dev.off()
predict_svm <- predict(tune_out_svm$best.model, newdata = train.data[, -1])
cf_svm_train <- confusionMatrix(predict_svm,as.factor(train.data$Class))
cf_svm_train <- as_tibble(cf_svm_train$table)
png(filename="~/Google Drive/My Drive/Dissertation- G drive/Arabi/sucrose_in_lateral_root/svm_train_final_suc_genes_cm.png", res=600, width=4000, height=4000, pointsize=10,)
plot_confusion_matrix(cf_svm_train, 
                      target_col = "Reference", 
                      prediction_col = "Prediction",
                      counts_col = "n")
dev.off()
prComp_test<-predict(prComp, newdata =testing[,-ncol(testing)])
test.data<-data.frame(Class = testing$Class, prComp_test[,1:8])
predict_test <- predict(tune_out_svm$best.model, newdata = test.data[, -1])
cf_svm_test <- confusionMatrix(predict_test,as.factor(test.data$Class))
cf_svm_test_tibble <- as_tibble(cf_svm_test$table)
png(filename="~/Google Drive/My Drive/Dissertation- G drive/Arabi/sucrose_in_lateral_root/svm_final_suc_genes_test_cm.png", res=600, width=4000, height=4000, pointsize=10,)
plot_confusion_matrix(cf_svm_test_tibble, 
                      target_col = "Reference", 
                      prediction_col = "Prediction",
                      counts_col = "n")
dev.off()



# HYPERPARAMETER TUNING RANDOM FOREST
seed <- 123
set.seed(seed)
tune_out_rf <- tune.randomForest(x = train.data[, -1], y = as.factor(train.data$Class),  type = "C-classification",
                     ntree = c(50, 100, 150, 200, 250, 300, 400, 500, 600), mtry = 1:8 , scale = FALSE)
performance_rf <- tune_out_rf$performances
predict_rf <- predict(tune_out_rf$best.model, newdata = train.data[, -1])
cf_rf_train <- confusionMatrix(predict_rf,as.factor(train.data$Class))
cf_rf_train <- as_tibble(cf_rf_train$table)
png(filename="~/Google Drive/My Drive/Dissertation- G drive/Arabi/sucrose_in_lateral_root/rf_final_suc_genes_train_cm.png", res=600, width=4000, height=4000, pointsize=10,)
plot_confusion_matrix(cf_rf_train, 
                      target_col = "Reference", 
                      prediction_col = "Prediction",
                      counts_col = "n")
dev.off()
predict_test_rf <- predict(tune_out_rf$best.model, newdata = test.data[, -1])
cf_rf_test <- confusionMatrix(predict_test_rf,as.factor(test.data$Class))
cf_rf_test <- as_tibble(cf_rf_test$table)
png(filename="~/Google Drive/My Drive/Dissertation- G drive/Arabi/sucrose_in_lateral_root/rf_final_suc_genes_test_cm.png", res=600, width=4000, height=4000, pointsize=10,)
plot_confusion_matrix(cf_rf_test, 
                      target_col = "Reference", 
                      prediction_col = "Prediction",
                      counts_col = "n")
dev.off()
g2mtry <- ggplot(performance_rf, aes(x= mtry, y=error, color=error))+ geom_point() + geom_smooth()+geom_point(data=performance_rf[rownames(tune_out_rf$best.parameters), ], aes(x= mtry, y=error), colour="red", size=5) 
g2ntree <- ggplot(performance_rf, aes(x= ntree, y=error, color=error, palette = "green"))+ geom_point() + geom_smooth()+geom_point(data=performance_rf[rownames(tune_out_rf$best.parameters), ], aes(x= ntree, y=error), colour="red", size=5)
g2both <- ggplot(performance_rf, aes(x= mtry, y=ntree, color=error, palette = "jco"))+ geom_point() + geom_smooth()+geom_point(data=performance_rf[rownames(tune_out_rf$best.parameters), ], aes(x=mtry, y=ntree), colour="red", size=5)
png(filename="~/Google Drive/My Drive/Dissertation- G drive/Arabi/sucrose_in_lateral_root/rf_tune_mtry_7_ntree_50_error_0.2218.png", res=600, width=8800, height=4800, pointsize=10,)
ggarrange(g2mtry, g2ntree, g2both, 
          labels = c("A", "B", "C"),
          ncol = 3, nrow = 1)
dev.off()


# HYPERPARAMETER TUNING NEURAL NETWORKS
seed <- 123
set.seed(seed)
tune_out_nn <- tune.nnet(x = Class~., data = data.frame(train.data),  type = "C-classification", size = 1:9,decay = c(0.0001, 0.0003, 0.0005, 0.001, 0.003, 0.005, 0.01, 0.03, 0.05, 0.1, 0.3, 0.5), scale = FALSE)
performance_nn <- tune_out_nn$performances
g3size <- ggplot(performance_nn, aes(x= size, y=error, color=error))+ geom_point() + geom_smooth()+geom_point(data=performance_nn[rownames(tune_out_nn$best.parameters), ], aes(x= size, y=error), colour="red", size=5) 
g3decay <- ggplot(performance_nn, aes(x= decay, y=error, color=error, palette = "green"))+ geom_point() + geom_smooth()+geom_point(data=performance_nn[rownames(tune_out_nn$best.parameters), ], aes(x= decay, y=error), colour="red", size=5)
g3both <- ggplot(performance_nn, aes(x= size, y=decay, color=error, palette = "jco"))+ geom_point() + geom_smooth()+geom_point(data=performance_nn[rownames(tune_out_nn$best.parameters), ], aes(x=size, y=decay), colour="red", size=5)
png(filename="~/Google Drive/My Drive/Dissertation- G drive/Arabi/sucrose_in_lateral_root/version 4/nn_tune_size_4_decay_0.3_error_0.3424.png", res=600, width=8800, height=4800, pointsize=10,)
ggarrange(g3size, g3decay, g3both, 
          labels = c("A", "B", "C"),
          ncol = 3, nrow = 1)
dev.off()
nnet_model <- nnet(Class~., data=train.data, size = 4,decay = 0.3)
predict_nn <- predict(nnet_model, train.data, type = "class")
cf_nn_train <- confusionMatrix(as.factor(predict_nn), train.data$Class)
cf_nn_train <- as_tibble(cf_nn_train$table)
png(filename="~/Google Drive/My Drive/Dissertation- G drive/Arabi/sucrose_in_lateral_root/version 4/nn_final_more_suc_genes_train_cm.png", res=600, width=4000, height=4000, pointsize=10,)
plot_confusion_matrix(cf_nn_train, 
                      target_col = "Reference", 
                      prediction_col = "Prediction",
                      counts_col = "n")
dev.off()

predict_nn_test <- predict(nnet_model, test.data, type = "class")
cf_nn_test <- confusionMatrix(as.factor(predict_nn_test), test.data$Class)
cf_nn_test <- as_tibble(cf_nn_test$table)
png(filename="~/Google Drive/My Drive/Dissertation- G drive/Arabi/sucrose_in_lateral_root/version 4/nn_final_more_suc_genes_test_cm.png", res=600, width=4000, height=4000, pointsize=10,)
plot_confusion_matrix(cf_nn_test, 
                      target_col = "Reference", 
                      prediction_col = "Prediction",
                      counts_col = "n")
dev.off()




# HYPERPARAMETER TUNING KNN
seed <- 123
set.seed(seed)
tune_out_knn <- tune.knn(x = train.data[, -1], y = as.factor(train.data$Class),  type = "C-classification", k = 1:25, scale = FALSE)
model_knn <- gknn(x = train.data[, -1], y = as.factor(train.data$Class),  type = "C-classification", k = 11, scale = FALSE)
predict_knn <- predict(model_knn, newdata = train.data[, -1])
confusionMatrix(predict_knn,as.factor(train.data$Class))
#prComp_test<-predict(prComp, newdata =testing[,-ncol(testing)])
#test.data<-data.frame(Class = testing$Class, prComp_test[,1:9])
predict_test_knn <- predict(model_knn, newdata = test.data[, -1])
confusionMatrix(predict_test_knn,as.factor(test.data$Class))




# feature matrix PCs
prComp_fmatrix<-prcomp(feature_matrix,center = TRUE, scale. = TRUE)
std_dev <- prComp_fmatrix$sdev
pr_var <- std_dev^2
prop_varex <- pr_var/sum(pr_var)
pcsum <- sum(prop_varex[1:8])
png(filename="~/Google Drive/My Drive/Dissertation- G drive/Arabi/sucrose_in_lateral_root/PC_8_fmatrix_0.9493.png", res=600, width=4000, height=4000, pointsize=10,)
plot(cumsum(prop_varex), xlab = "Principal Component",ylab = "Cumulative Proportion of Variance Explained",type = "b")
abline(h=pcsum,col='red',v=8)
dev.off()
feature_matrix_new <- data.frame(prComp_fmatrix$x)
feature_matrix_new <- feature_matrix_new[, 1:8]
```


### Find optimal score using a 10-fold cross-validation based on the previously set hyperparameters
```{r find_optimiser_score, echo=TRUE}

cvRes <- cross_validation(seed = seed, method = "svm", featureMat = feature_matrix_new, positives = positiveSamples, negatives = negativeSamples, cross = 10, cpus = 15, gamma = 0.1, cost = 5, kernel = "radial", plot = TRUE ) ##parameters for SVM algorithm

cvRes <- cross_validation(seed = seed, method = "randomForest", featureMat = feature_matrix_new, positives = positiveSamples, negatives = negativeSamples, cross = 10, cpus = 15, ntree = 50, mtry = 7, plot = TRUE ) ##parameters for random forest algorithm

cvRes <- cross_validation(seed = seed, method = "nnet", featureMat = feature_matrix_new, positives = positiveSamples, negatives = negativeSamples, cross = 10, cpus = 15, size = 4, decay = 0.3, plot = TRUE ) ##parameters for neural network algorithm

cvRes <- cross_validation(seed = seed, method = "knn", featureMat = feature_matrix_new, positives = positiveSamples, negatives = negativeSamples, cross = 5, cpus = 15, k = 6, plot = TRUE )##parameters for knn algorithm

positiveSampleScores <- cvRes[[1]]$positives.test.score
negativeSampleScores <- cvRes[[1]]$negatives.test.score

## execute the optimal score function to plot the optimal score corresponding to the highest F-score
optimal_score <- optimalScore( positiveSampleScores, negativeSampleScores, beta = 0.00001, plot = TRUE )
#the optimal threshold
optimal_score$optimalScore
#statistic results for different threshold of prediction scores
optimal_score$statMat[1:10,]

```



### Implementing the PSOL algorithm
```{r PSOL, echo=FALSE}

# running the PSOL algo based on an optimal prediction score
PSOL_NegativeExpansion <- function( featureMat, positives, negatives, unlabels, cpus = 16, iterator = 50, cross = 5, score = 0.98, method = c("randomForest", "svm", "nnet", "knn" ), plot = TRUE, trace = TRUE, PSOLResDic, ... ) {

  call <- match.call()

  ##create PSOLResDic
  dir.create( path = PSOLResDic, showWarnings = FALSE)

  if( score > 1.0 | score < 0 )
     stop("Error: score is a value ranged from 0 to 1.")
  if( is.null(rownames(featureMat)) )
    stop("Error: rownames should be given to featureMat")

  ##get the thresholdIdx-th top prediction score of positive samples as the threshold cutoff
  #thresholdIdx <- floor( (1.0 - TPR)*length(positives) )
  #if( thresholdIdx <= 0 )
   # thresholdIdx <- 1

  finalUnlabels <- unlabels
  finalNegatives <- negatives
  negCount <- length(finalNegatives)
  
  numMat <- matrix(0, nrow = iterator, ncol = 5 )
  rownames(numMat) <- paste("Iter", 1:iterator, sep = "" )
  colnames(numMat) <- c("IterNo", "AUC_On_TrainingDataSet", "AUC_On_TestingDataSet", "Negative_Sample_Num", "Unlabeled_Sample_Num")
  numMat[,1] <- 1:iterator

  ##check samples
  if( length( setdiff( c( positives, negatives, unlabels), rownames(featureMat) ) ) > 0 ) {
    stop("Error: some samples not included in the featureMat.\n")
  }
  featureMat <- featureMat[c( positives, negatives, unlabels), ]
  
  
  zeroNumCount = 0
  iter <- 0
  while( negCount <= length(unlabels) ){
    
    iter <- iter + 1
    if( iter > iterator ){
      iter <- iter - 1
      break
    }
    #cross validation   
    permutRes <- cross_validation( seed = randomSeed(), method = method, featureMat = featureMat, positives = positives, negatives = finalNegatives, cross = cross, cpus = cpus, ... )
    
    ##find classifier with max AUC, and re-calculate prediction scores of positive and unlable samples
    maxAUC_Classifer <- find_ClassifierWithMaxAUC( permutRes )
    prediction.score <- predictor( method = method, classifier = maxAUC_Classifer$classifier, featureMat = featureMat ) 
    
    # if the gene has a prediction score higher than the optimal score, it remains in the unlabelled set
    # if the gene has a prediction score lower than the optimal score, it is added to the negative set.
    positives.score <- sort( prediction.score[positives], decreasing = FALSE )
    negatives.score <- prediction.score[finalNegatives] 
    unlabels.score <- prediction.score[finalUnlabels]

    #positive.Threshold <- as.numeric( positives.score[thresholdIdx] ) 
    positive.Threshold <- score #threshold
    num <- length( which( unlabels.score < positive.Threshold) ) 
    finalUnlabels <- names(unlabels.score[which(unlabels.score > positive.Threshold)])
    finalNegatives <- unique( c( names(unlabels.score[which(unlabels.score <= positive.Threshold)]), finalNegatives) )  

    AUCMat <- obtain_CV_AUCMat( permutRes )
    numMat[iter, 2] <- mean(AUCMat[,1]) #AUC on training dataset
    numMat[iter, 3] <- mean(AUCMat[,2]) #AUC on testing dataset
    numMat[iter, 4] <- length(negatives.score)
    numMat[iter, 5] <- length(unlabels.score)
    
    #plot density
#    if( plot == TRUE ) {
#       pdf( paste( PSOLResDic, "PSOL_Iteration_", iter, ".pdf", sep = ""), height= 5, width= 10)
#       par(mfrow=c(1,2))
#       density.p <- density(positives.score)
#       density.n <- density(unlabels.score)
#       xrange = range(density.p$x, density.n$x)
#       yrange = range(density.p$y, density.n$y)
#       plot( density.p, xlim = xrange, ylim = yrange, col = "red", xlab="prediction score", ylab = "density", main = paste("iterator times:", iter, sep="" ) )
#       lines(density.n, col = "black")
#       abline( v = positive.Threshold, col = "gray" )
    
       #plot differences of AUC
#       boxplot(AUCMat, ylim = c(0,1) )
#       dev.off()
#    } 
        
    #save result
    if( trace == TRUE ) {
       resultDir <- paste( PSOLResDic, "PSOL_Iteration_", iter, ".RData", sep = "")
       iterRes <- list( permutRes = permutRes, method = method, classifier = maxAUC_Classifer, 
                     predictionScores = prediction.score, negativeScores = negatives.score, 
                     unlabelScores = unlabels.score, threshold = positive.Threshold, 
                     positives = positives, negatives = names(positives.score), unlabels = names(unlabels.score), #here negatives mean the "negatives" started at this iteration time. 
                     finalNegatives = finalNegatives, finalUnlabels = finalUnlabels )
       save( iterRes, file = resultDir )
    }
    
    cat( "\nPSOL_Iteration: ", iter, "\tAUC: ", numMat[iter, 3], "\tCurrentPosNum:", length(positives),  "\tCurrentNegNum: ", numMat[iter, 4], "\tCurrentUnlabelNum: ", numMat[iter, 5], "\tIncreased negatives Num: ", num, "\n")
     
  }##end while
  
  ##plot number distribution
  numMat <- numMat[1:iter,]
  write.table( numMat, paste( PSOLResDic, "PSOL_NegativeIncreasement.txt", sep="" ), sep = "\t", quote = F )
  if( plot == TRUE ) {
    if( !require(gplots) ) {
       install.packages("gplots")
       require(gplots)
    }
    

    pdf( paste( PSOLResDic, "PSOL_NegativeIncreasement.pdf", sep="" ), height= 10, width = 10 )  
    par(mar=c(5, 12, 4, 4) + 0.1)
    plot(numMat[,1], numMat[,3], axes=F, ylim=c(0,1.0), xlab="", ylab="",type="l",col="red", main="")
    points(numMat[,1],numMat[,3],pch=20,col="red", cex = 0.8)
    axis(2, ylim=c(0,1.0),col="red",lwd=2)
    mtext(2,text="AUC",line=2)
  
    par(new=T)
    plot(numMat[,1], numMat[,4], axes=F, ylim=c(0,max(numMat[,4])), xlab="", ylab="", type="l", col = "black", lty=2, main="",lwd=2)
    axis( 2, ylim=c(0,max(numMat[,4])), lwd=2, line=3.5, col = "black" )
    points(numMat[,1], numMat[,4], pch=20, col = "black", cex = 0.8)
    mtext(2,text="Number of \"filtered-out\" genes ",line=5.5)
  
    axis(1,numMat[,1] )
    mtext("Iteration Number",side=1,col="black",line=2)
    #legend("bottomright",legend=c("negatives","benchmark genes"),lty=c(1,2), col = c("black", "red") )
    dev.off()
  }
   
}


##################################################
##get iteration result
PSOL_ResultExtraction <- function( PSOLResDic, iterations = c(1:4) ) {
  if( length(iterations) == 1 & is.null(iterations) )
    stop("Error: iteration numbers need to be specified.")
  
  resmat <- NULL
  sumFile <- paste(PSOLResDic, "PSOL_NegativeIncreasement.txt", sep = "" )
  if( file.exists(sumFile)){
     resmat <- as.matrix( read.table(sumFile, sep = "\t", quote = "") )
  }else{
     stop("Error: file PSOL_NegativeIncreasement.txt was not generated whiling running the function PSOL_NegativeExpansion\n")
  }
  
  reslist <- list()
  for( ii in 1:length(iterations) ) {
    curIter <- iterations[ii]
    AUC <- NULL
    positives <- NULL
    negatives <- NULL
    unlabels <- NULL
 
    iterRes <- NULL
    if( exists("iterRes") )
       rm(iterRes)
    load( paste( PSOLResDic, "PSOL_Iteration_", curIter, ".RData", sep = ""))
    if( exists("iterRes") ){
      positives <- iterRes$positives
      negatives <- iterRes$negatives
      unlabels <- iterRes$unlabels
    }else{
      stop("Error: fail to load POSL result at the initial negative selection.")
    }

    AUC <- resmat[ paste("Iter", curIter, sep = ""), "AUC_On_TestingDataSet"]
    reslist[[curIter]] <- list( AUC = AUC, positives = positives, negatives = negatives, unlabels = unlabels)
  }#end for ii
  reslist
}

```


### Running the PSOL algorithm with various model parameters
```{r run_PSOL, echo=TRUE}


PSOLResDic = "~/Google Drive/My Drive/Dissertation- G drive/Arabi/sucrose_in_lateral_root/svm/"

PSOL_NegativeExpansion(featureMat = feature_matrix_new, positives = positiveSamples, negatives = negativeSamples, unlabels = unlabelSamples, cpus = 15, iterator = 15, cross = 10, score = 0.290, method = "svm", plot = TRUE, trace = TRUE, PSOLResDic = PSOLResDic, gamma = 0.1, cost = 5, kernel = "radial")


unregister_dopar <- function() {
  env <- foreach:::.foreachGlobals
  rm(list=ls(name=env), pos=env)
}

unregister_dopar()


```

## GSEA ANALYSIS WITH CLUSTERPROFILER 
```{r cluster_profiler, echo=TRUE}
feature_matrix_df <- as.data.frame(root_math)
organism = "org.At.tair.db"
cluster_df <- sucrose_genes
cluster_df <- as.data.frame(cluster_df)
rownames(cluster_df) <- cluster_df$cluster_df
feature_matrix_df_de <- feature_matrix_df[sucrose_genes, ]
cluster_df$log2FoldChange <- feature_matrix_df_de$log2FoldChange

sorted_dfx <- cluster_df$log2FoldChange
names(sorted_dfx) <- cluster_df$cluster_df
sorted_dfx <- sort(sorted_dfx, decreasing = TRUE)


keytypes(org.At.tair.db)
gse <- gseGO(geneList=sorted_dfx, 
             ont ="ALL", 
             keyType = "TAIR", 
             minGSSize = 3, 
             maxGSSize = 800, 
             pvalueCutoff = 0.05, 
             verbose = TRUE, 
             OrgDb = organism,
             nPerm = 10000,
             pAdjustMethod = "none")

d <- godata('org.At.tair.db', ont="BP")
require(DOSE)
library(enrichplot)
library(DOSE)

# enriched map plot
ego2 <- pairwise_termsim(gse, method="Wang", semData = d)
png(filename="~/Google Drive/My Drive/Dissertation- G drive/Arabi/sucrose_in_lateral_root/net1x.png", res=600, width=4800, height=4800, pointsize=10,)
emapplot(ego2)
dev.off()

# clustered enriched map plot
png(filename="~/Google Drive/My Drive/Dissertation- G drive/Arabi/sucrose_in_lateral_root/net2x.png", res=600, width=4800, height=4800, pointsize=10,)
emapplot_cluster(ego2)
dev.off()

# cnet plot
png(filename="~/Google Drive/My Drive/Dissertation- G drive/Arabi/sucrose_in_lateral_root/net3x.png", res=600, width=4800, height=4800, pointsize=10,)
cnetplot(gse, categorySize="pvalue", foldChange=sorted_dfx, showCategory = 3)
dev.off()

# ridge plot
png(filename="~/Google Drive/My Drive/Dissertation- G drive/Arabi/sucrose_in_lateral_root/net4x.png", res=600, width=6800, height=11000, pointsize=10,)
ridgeplot(gse) + labs(x = "enrichment distribution")
dev.off()

png(filename="~/Google Drive/My Drive/Dissertation- G drive/Arabi/sucrose_in_lateral_root/net5x.png", res=600, width=4800, height=4800, pointsize=10,)
gseaplot(gse, by = "all", title = gse$Description[1], geneSetID = 1)
dev.off()

terms <- gse$Description[1:3]
png(filename="~/Google Drive/My Drive/Dissertation- G drive/Arabi/sucrose_in_lateral_root/net6x.png", res=600, width=4800, height=4800, pointsize=10,)
pmcplot(terms, 2010:2022, proportion=FALSE)
dev.off()
```

### CLUSTER PROFILER ENRICHED KEGG PATHWAYS
```{r cluster_profiler_kegg, echo=TRUE}
original_gene_list <- cluster_df$log2FoldChange
names(original_gene_list) <- cluster_df$cluster_df
ids<-bitr(names(original_gene_list), fromType = "TAIR", toType = "ENTREZID", OrgDb=organism)
 # remove duplicate IDS (here I use "ENSEMBL", but it should be whatever was selected as keyType)
dedup_ids = ids[!duplicated(ids[c("TAIR")]),]

# Create a new dataframe df2 which has only the genes which were successfully mapped using the bitr function above
df2 = cluster_df[rownames(cluster_df) %in% dedup_ids$TAIR,]

# Create a new column in df2 with the corresponding ENTREZ IDs
df2$Y = dedup_ids$ENTREZID

# Create a vector of the gene unuiverse
kegg_gene_list <- df2$log2FoldChange

# Name vector with ENTREZ ids
names(kegg_gene_list) <- df2$Y

# omit any NA values 
kegg_gene_list<-na.omit(kegg_gene_list)

# sort the list in decreasing order (required for clusterProfiler)
kegg_gene_list = sort(kegg_gene_list, decreasing = TRUE)

#save(kegg_gene_list, file = "kegg_gene_list.Rdata")
kegg_organism = "ath"
kk2 <- gseKEGG(geneList     = kegg_gene_list,
               organism     = kegg_organism,
               nPerm        = 10000,
               minGSSize    = 3,
               maxGSSize    = 800,
               pvalueCutoff = 0.05,
               pAdjustMethod = "none",
               keyType       = "ncbi-geneid")

# enriched map plot
kkegg <- pairwise_termsim(kk2, method="JC", semData = d)
png(filename="~/Google Drive/My Drive/Dissertation- G drive/Arabi/sucrose_in_lateral_root/keggnet1x.png", res=600, width=4800, height=4800, pointsize=10,)
emapplot(kkegg)
dev.off()

# clustered enriched map plot
png(filename="~/Google Drive/My Drive/Dissertation- G drive/Arabi/sucrose_in_lateral_root/keggnet2x.png", res=600, width=4800, height=4800, pointsize=10,)
emapplot_cluster(kkegg)
dev.off()

# ridge plot
png(filename="~/Google Drive/My Drive/Dissertation- G drive/Arabi/sucrose_in_lateral_root/keggnet3x.png", res=600, width=4800, height=4800, pointsize=10,)
ridgeplot(kk2) + labs(x = "enrichment distribution")
dev.off()

# cnet plot
png(filename="~/Google Drive/My Drive/Dissertation- G drive/Arabi/sucrose_in_lateral_root/keggnet4x.png", res=600, width=4800, height=4800, pointsize=10,)
cnetplot(kk2, categorySize="pvalue", foldChange=sorted_dfx)
dev.off()

png(filename="~/Google Drive/My Drive/Dissertation- G drive/Arabi/sucrose_in_lateral_root/keggnet5x.png", res=600, width=4800, height=4800, pointsize=10,)
gseaplot(kk2, by = "all", title = kk2$Description[1], geneSetID = 1)
dev.off()

```

### ENRICHED KEGG PATHWAYS TO HIGHLIGHT THE CANDIDATE GENES BASED ON FOLD CHANGE
```{r KEGG_pathways, echo=FALSE}

for (i in kk2$ID)
{
  
dme <- pathview(gene.data=kegg_gene_list, pathway.id=i, species = kegg_organism)
  
dme <- pathview(gene.data=kegg_gene_list, pathway.id=i, species = kegg_organism, kegg.native = F)
  #
} 
```




 